{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c3608e28",
      "metadata": {
        "id": "c3608e28"
      },
      "source": [
        "# Домашнее задание №15. Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef5ec029",
      "metadata": {
        "id": "ef5ec029"
      },
      "source": [
        "## Задание 1\n",
        "1. Самостоятельно выбранными средствами (opencv, pillow (PIL), …) сгенерировать по 820 картинок размером 100х100 пикселей (px) для каждой из цифр: 0, 1, 3, 8 следующим образом (800 – тренировочная выборка, 20 – тестовая выборка № 1):\n",
        "* фон картинки белый,\n",
        "* цифра: ширина – 20 px, высота – 50 px, цвет линии – черный, цифра целиком помещается в картинку, цифра находится в случайном месте на картинке,\n",
        "* на изображении цифра расположена так, что ее вертикальная ось параллельна оси ординат (вертикальное положение) или оси абсцисс (горизонтальное положение),\n",
        "* тренировочная выборка содержит 400 изображений каждой цифры в горизонтальном положении и 400 изображений каждой цифры в вертикальном положении,\n",
        "* тестовая выборка содержит 10 изображений каждой цифры в горизонтальном положении и 10 изображений каждой цифры в вертикальном положении,\n",
        "\n",
        "2. Создать новые тестовые картинки, полученные путем добавления черных пикселей (шум) в случайно выбранные места сгенерированных тестовых картинок:\n",
        "* 20 пикселей (тестовая выборка № 2),\n",
        "* 50 пикселей (тестовая выборка № 3),\n",
        "* 100 пикселей (тестовая выборка № 4),\n",
        "* 200 пикселей (тестовая выборка № 5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b93e7027",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b93e7027",
        "outputId": "a4988fa5-20e0-46be-e838-3991b067719f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Всё\n"
          ]
        }
      ],
      "source": [
        "# Напишите свой код в данной ячейке\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "gc_folder = r\"/content/gdrive/My Drive/Цифровая кафедра/15/\"\n",
        "train = gc_folder + 'train/'\n",
        "first = gc_folder +'1/'\n",
        "\n",
        "def create_image(digit, orientation, directory, i):\n",
        "  img = np.ones((100, 100, 3), dtype=np.uint8) * 255\n",
        "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "  font_scale = 2\n",
        "  thickness = 2\n",
        "  text_size = cv2.getTextSize(digit, font, font_scale, thickness)[0]\n",
        "\n",
        "  if orientation == \"horizontal\":\n",
        "    img = np.ones((100, 100, 3), dtype=np.uint8) * 255\n",
        "    x = random.randint(0, 100 - text_size[1])\n",
        "    y = random.randint(text_size[0], 100)\n",
        "    cv2.putText(img, digit, (x, y), font, font_scale, (0, 0, 0), thickness)\n",
        "    img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "  elif orientation == \"vertical\":\n",
        "    x = random.randint(0, 100 - text_size[0])\n",
        "    y = random.randint(text_size[1], 100)\n",
        "    cv2.putText(img, digit, (x, y), font, font_scale, (0, 0, 0), thickness)\n",
        "  cv2.imwrite(directory + f'{digit}_{orientation}_{i}.png', img)\n",
        "\n",
        "digits = ['0', '1', '3', '8']\n",
        "\n",
        "for digit in digits:\n",
        "  i = 0\n",
        "  for _ in range(400):\n",
        "    i += 1\n",
        "    create_image(digit, 'horizontal', train+f'{digit}/', i)\n",
        "    create_image(digit, 'vertical', train+f'{digit}/', i)\n",
        "\n",
        "for digit in digits:\n",
        "  i = 0\n",
        "  for _ in range(10):\n",
        "    i += 1\n",
        "    create_image(digit, 'horizontal', first+f'{digit}/', i)\n",
        "    create_image(digit, 'vertical', first+f'{digit}/', i)\n",
        "\n",
        "print(\"Всё\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a16CazQ679E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a16CazQ679E",
        "outputId": "b42f983f-cd05-4d62-d060-55f8b3169298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Всё\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "gc_folder = r\"/content/gdrive/My Drive/Цифровая кафедра/15/\"\n",
        "train = gc_folder + 'train/'\n",
        "first = gc_folder + '1/'\n",
        "second = gc_folder +'2/'\n",
        "third = gc_folder +'3/'\n",
        "fourth = gc_folder + '4/'\n",
        "fifth = gc_folder + '5/'\n",
        "digits = ['0', '1', '3', '8']\n",
        "noise_levels = [20, 50, 100, 200]\n",
        "\n",
        "def add_noise(image, num_pixels):\n",
        "  noisy_image = image.copy()\n",
        "  height, width, _ = noisy_image.shape\n",
        "  for _ in range(num_pixels):\n",
        "    x = random.randint(0, width - 1)\n",
        "    y = random.randint(0, height - 1)\n",
        "    noisy_image[y, x] = [0, 0, 0]\n",
        "  return noisy_image\n",
        "\n",
        "def create_noisy_test_images(begin_folder, noise_level, end_folder):\n",
        "  for filename in os.listdir(begin_folder):\n",
        "    if filename.endswith('.png'):\n",
        "      img_path = os.path.join(begin_folder, filename)\n",
        "      image = cv2.imread(img_path)\n",
        "      noisy_image = add_noise(image, noise_level)\n",
        "      noisy_img_path = os.path.join(end_folder, f'{filename}')\n",
        "      cv2.imwrite(noisy_img_path, noisy_image)\n",
        "\n",
        "for digit in digits:\n",
        "  i = 1\n",
        "  create_noisy_test_images(first+f'{digit}/', 20, second+f'{digit}/')\n",
        "  create_noisy_test_images(first+f'{digit}/', 50, third+f'{digit}/')\n",
        "  create_noisy_test_images(first+f'{digit}/', 100, fourth+f'{digit}/')\n",
        "  create_noisy_test_images(first+f'{digit}/', 200, fifth+f'{digit}/')\n",
        "print(\"Всё\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3360dc",
      "metadata": {
        "id": "6d3360dc"
      },
      "source": [
        "# Задание №2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30b0459a",
      "metadata": {
        "id": "30b0459a"
      },
      "source": [
        "Не используя предобученные модели (сети), модифицировать скрипт задачи «Dogs vs Cats» (с семинара) или написать свою нейронную сеть на keras такую, что:\n",
        "\n",
        "1) На вход подается тренировочное множество: по 800 картинок каждой цифры.\n",
        "2) Из тренировочного множества выделяется часть картинок (10-20%), на валидационное множество, в котором должны присутствовать цифры в вертикальном и горизонтальном положении.\n",
        "3) Протестировать адекватность модели на всех тестовых выборках № 1, № 2, № 3, № 4, № 5, фиксируя при этом точность (accuracy) классификации.\n",
        "4) Повторить пункты 1)–3), изменив объем тренировочной выборки до 600, 400, 200, 100 картинок каждой цифры.\n",
        "\n",
        "<i> Могут пригодиться <tt>Dense</tt>, <tt>Conv2D</tt>, <tt>MaxPooling2D</tt>, <tt>Flatten</tt>.</i>\n",
        "\n",
        "Результаты оформить в виде таблицы со столбцами: размер тренировочной выборки, количество шумовых пикселей, точность (accuracy) классификации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb46050",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cb46050",
        "outputId": "bd6946ba-b9f9-4b04-b8f6-d873438f1245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "800 изображений\n",
            "3200\n",
            "Loaded 3200 images and 3200 labels\n",
            "Epoch 1/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 510ms/step - accuracy: 0.2928 - loss: 1.4900 - val_accuracy: 0.6708 - val_loss: 0.7524\n",
            "Epoch 2/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 486ms/step - accuracy: 0.8086 - loss: 0.4852 - val_accuracy: 0.9479 - val_loss: 0.1626\n",
            "Epoch 3/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 471ms/step - accuracy: 0.9808 - loss: 0.0821 - val_accuracy: 0.9896 - val_loss: 0.0483\n",
            "Epoch 4/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 495ms/step - accuracy: 0.9990 - loss: 0.0157 - val_accuracy: 0.9917 - val_loss: 0.0311\n",
            "Epoch 5/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 503ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9875 - val_loss: 0.0338\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "600 изображений\n",
            "3200\n",
            "Loaded 3200 images and 3200 labels\n",
            "Epoch 1/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 480ms/step - accuracy: 0.3036 - loss: 1.5917 - val_accuracy: 0.7563 - val_loss: 0.5981\n",
            "Epoch 2/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 474ms/step - accuracy: 0.8558 - loss: 0.3917 - val_accuracy: 0.9458 - val_loss: 0.1632\n",
            "Epoch 3/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 493ms/step - accuracy: 0.9854 - loss: 0.0663 - val_accuracy: 0.9792 - val_loss: 0.0694\n",
            "Epoch 4/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 537ms/step - accuracy: 0.9925 - loss: 0.0197 - val_accuracy: 0.9958 - val_loss: 0.0333\n",
            "Epoch 5/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 501ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9958 - val_loss: 0.0305\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "400 изображений\n",
            "3200\n",
            "Loaded 3200 images and 3200 labels\n",
            "Epoch 1/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 487ms/step - accuracy: 0.3385 - loss: 1.6728 - val_accuracy: 0.7229 - val_loss: 0.6298\n",
            "Epoch 2/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 467ms/step - accuracy: 0.7779 - loss: 0.5148 - val_accuracy: 0.8833 - val_loss: 0.3105\n",
            "Epoch 3/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 489ms/step - accuracy: 0.9076 - loss: 0.2446 - val_accuracy: 0.9521 - val_loss: 0.1623\n",
            "Epoch 4/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 466ms/step - accuracy: 0.9728 - loss: 0.1053 - val_accuracy: 0.9604 - val_loss: 0.1276\n",
            "Epoch 5/5\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 453ms/step - accuracy: 0.9943 - loss: 0.0426 - val_accuracy: 0.9688 - val_loss: 0.0917\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "200 изображений\n",
            "1600\n",
            "Loaded 1600 images and 1600 labels\n",
            "Epoch 1/5\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 466ms/step - accuracy: 0.2324 - loss: 1.8986 - val_accuracy: 0.5833 - val_loss: 1.0815\n",
            "Epoch 2/5\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 453ms/step - accuracy: 0.6731 - loss: 0.8399 - val_accuracy: 0.6500 - val_loss: 0.7142\n",
            "Epoch 3/5\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 465ms/step - accuracy: 0.8056 - loss: 0.4572 - val_accuracy: 0.8208 - val_loss: 0.4577\n",
            "Epoch 4/5\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 470ms/step - accuracy: 0.9159 - loss: 0.2686 - val_accuracy: 0.8750 - val_loss: 0.3226\n",
            "Epoch 5/5\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 490ms/step - accuracy: 0.9499 - loss: 0.1684 - val_accuracy: 0.8792 - val_loss: 0.2829\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "100 изображений\n",
            "800\n",
            "Loaded 800 images and 800 labels\n",
            "Epoch 1/5\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 506ms/step - accuracy: 0.2475 - loss: 2.4122 - val_accuracy: 0.2583 - val_loss: 1.3774\n",
            "Epoch 2/5\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 458ms/step - accuracy: 0.3211 - loss: 1.3406 - val_accuracy: 0.3167 - val_loss: 1.2778\n",
            "Epoch 3/5\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 480ms/step - accuracy: 0.5701 - loss: 1.0180 - val_accuracy: 0.5750 - val_loss: 0.9424\n",
            "Epoch 4/5\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 594ms/step - accuracy: 0.7773 - loss: 0.5739 - val_accuracy: 0.6583 - val_loss: 0.9771\n",
            "Epoch 5/5\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 403ms/step - accuracy: 0.8023 - loss: 0.4754 - val_accuracy: 0.5833 - val_loss: 0.9783\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "80\n",
            "Loaded 80 images and 80 labels\n",
            "    train_size  noise_pixels  accuracy\n",
            "0          800             0    1.0000\n",
            "1          800            20    0.9750\n",
            "2          800            50    0.5375\n",
            "3          800           100    0.2500\n",
            "4          800           200    0.2500\n",
            "5          600             0    0.9875\n",
            "6          600            20    0.9625\n",
            "7          600            50    0.3375\n",
            "8          600           100    0.2500\n",
            "9          600           200    0.2500\n",
            "10         400             0    0.9125\n",
            "11         400            20    0.9625\n",
            "12         400            50    0.4125\n",
            "13         400           100    0.2500\n",
            "14         400           200    0.2500\n",
            "15         200             0    0.8125\n",
            "16         200            20    0.7500\n",
            "17         200            50    0.2500\n",
            "18         200           100    0.2500\n",
            "19         200           200    0.2500\n",
            "20         100             0    0.6500\n",
            "21         100            20    0.6500\n",
            "22         100            50    0.6375\n",
            "23         100           100    0.7250\n",
            "24         100           200    0.3250\n"
          ]
        }
      ],
      "source": [
        "# Напишите свой код в данной ячейке\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "gc_folder = r\"/content/gdrive/My Drive/Цифровая кафедра/15/\"\n",
        "train = gc_folder + 'train/'\n",
        "test_folders = [gc_folder + f'{i}/' for i in range(1,6)]\n",
        "\n",
        "SEED = 42\n",
        "DIGITS = ['0', '1', '3', '8']\n",
        "IMG_SIZE = (100, 100)\n",
        "noise_levels = [0, 20, 50, 100, 200]\n",
        "\n",
        "def load_dataset(path, limit=None):\n",
        "  X = []\n",
        "  y = []\n",
        "  label_map = {digit: i for i, digit in enumerate(DIGITS)}\n",
        "  for digit in DIGITS:\n",
        "    v = [f for f in os.listdir(path+f'{digit}/') if 'vertical' in f]\n",
        "    h = [f for f in os.listdir(path+f'{digit}/') if 'horizontal' in f]\n",
        "    if limit:\n",
        "      v = v[:limit]\n",
        "      h = h[:limit]\n",
        "    for filename in v+h:\n",
        "      img_path = os.path.join(path, digit, filename)\n",
        "      img = Image.open(img_path).resize(IMG_SIZE)\n",
        "      X.append(np.array(img))\n",
        "      y.append(label_map[digit])\n",
        "  X = np.array(X).reshape(-1, 100, 100, 3) / 255.0\n",
        "  y = tf.keras.utils.to_categorical(y, num_classes=4)\n",
        "  return X, y\n",
        "\n",
        "def build_model():\n",
        "  model = Sequential([\n",
        "      Input(shape=(100, 100, 3)),  # Входной слой, ожидает изображения размером 100x100 пикселей с 3 каналами (RGB)\n",
        "      Conv2D(32, (3,3), activation='relu'),  # Сверточный слой с 32 фильтрами размером 3x3\n",
        "      MaxPooling2D((2,2)),  # Слой подвыборки с размером 2x2\n",
        "      Conv2D(64, (3,3), activation='relu'),  # Cверточный слой с 64 фильтрами размером 3x3\n",
        "      MaxPooling2D((2,2)),  # Слой подвыборки с размером 2x2\n",
        "      Flatten(),  # Преобразование многомерных данных в одномерные, чтобы передать в полносвязные слои\n",
        "      Dense(64, activation='relu'),  # Полносвязный слой с 64 нейронами\n",
        "      Dense(4, activation='softmax')  # Выходной слой с 4 нейронами (0,1,3,8)\n",
        "  ])\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def evaluate_on_tests(model):\n",
        "    results = []\n",
        "    for i, folder in enumerate(test_folders):\n",
        "      X_test, y_test = load_dataset(folder)\n",
        "      loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "      results.append((folder, acc))\n",
        "    return results\n",
        "\n",
        "train_sizes = [800, 600, 400, 200, 100]\n",
        "results_table = []\n",
        "\n",
        "for size in train_sizes:\n",
        "  print(f\"{size} изображений\")\n",
        "  X_train, y_train = load_dataset(train, limit=size)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=SEED,\n",
        "                                                    stratify=np.argmax(y_train, axis=1))\n",
        "\n",
        "  model = build_model()\n",
        "  model.fit(X_train, y_train, epochs=5, batch_size=32,\n",
        "            validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "  test_results = evaluate_on_tests(model)\n",
        "  for idx, (test_name, acc) in enumerate(test_results):\n",
        "      noise_level = noise_levels[idx]\n",
        "      results_table.append({\n",
        "          'train_size': size,\n",
        "          'noise_pixels': noise_level,\n",
        "          'accuracy': acc\n",
        "      })\n",
        "\n",
        "df = pd.DataFrame(results_table)\n",
        "print(df)\n",
        "df.to_excel('results_accuracy.xlsx', index=False, engine='openpyxl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}